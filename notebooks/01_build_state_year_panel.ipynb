{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 — Build State-Year Panel\n",
    "\n",
    "Loads **pre-fetched** SAIPE state-year data (parquet) and BLS LAUS unemployment (txt), cleans them, merges into a single panel, and saves to `data/processed/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: 3.12.9\n",
      "platform: Windows-11-10.0.26200-SP0\n",
      "pandas: 2.3.3\n",
      "numpy: 2.3.5\n"
     ]
    }
   ],
   "source": [
    "import sys, platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"python:\", sys.version.split()[0])\n",
    "print(\"platform:\", platform.platform())\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: C:\\projects\\python-policy-project\\notebooks\n",
      "Repo: C:\\projects\\python-policy-project\n",
      "Raw files: ['la.area.txt', 'la.series.txt', 'laus_allstates_u.txt', 'saipe_state_year.parquet']\n",
      "Processed dir: C:\\projects\\python-policy-project\\data\\processed\n",
      "✅ Found all required raw inputs\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =====================================================\n",
    "# Repo + paths (works even if kernel starts outside repo)\n",
    "# =====================================================\n",
    "\n",
    "START = Path.cwd().resolve()\n",
    "\n",
    "def find_repo(start: Path) -> Path:\n",
    "    # Find repo root by locating data/raw containing required inputs.\n",
    "    roots = [start]\n",
    "    if start.drive:\n",
    "        roots.append(Path(start.drive + \"\\\\\") / \"projects\")\n",
    "\n",
    "    required_raw_files = [\n",
    "        \"saipe_state_year.parquet\",\n",
    "        \"laus_allstates_u.txt\",\n",
    "        \"la.area.txt\",\n",
    "        \"la.series.txt\",\n",
    "    ]\n",
    "\n",
    "    seen = set()\n",
    "    for root in roots:\n",
    "        root = root.resolve()\n",
    "        if root in seen or not root.exists():\n",
    "            continue\n",
    "        seen.add(root)\n",
    "\n",
    "        for raw_dir in root.rglob(\"data/raw\"):\n",
    "            if all((raw_dir / f).exists() for f in required_raw_files):\n",
    "                return raw_dir.parent.parent  # .../data/raw -> repo root\n",
    "\n",
    "    raise RuntimeError(\n",
    "        f\"Could not find repo root from start={start}. \"\n",
    "        f\"Expected data/raw containing: {required_raw_files}\"\n",
    "    )\n",
    "\n",
    "REPO = find_repo(START)\n",
    "RAW = REPO / \"data\" / \"raw\"\n",
    "PROCESSED = REPO / \"data\" / \"processed\"\n",
    "PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAIPE_PATH = RAW / \"saipe_state_year.parquet\"\n",
    "LAUS_DATA_PATH = RAW / \"laus_allstates_u.txt\"\n",
    "LAUS_AREA_PATH = RAW / \"la.area.txt\"\n",
    "LAUS_SERIES_PATH = RAW / \"la.series.txt\"\n",
    "\n",
    "print(\"CWD:\", START)\n",
    "print(\"Repo:\", REPO)\n",
    "print(\"Raw files:\", [p.name for p in sorted(RAW.glob('*'))])\n",
    "print(\"Processed dir:\", PROCESSED)\n",
    "\n",
    "for p in [SAIPE_PATH, LAUS_DATA_PATH, LAUS_AREA_PATH, LAUS_SERIES_PATH]:\n",
    "    assert p.exists(), f\"Missing required input: {p}\"\n",
    "\n",
    "print(\"✅ Found all required raw inputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAIPE shape: (1581, 6)\n",
      "SAIPE columns: ['state', 'state_name', 'state_fips', 'year', 'poverty_rate', 'median_income']\n",
      "SAIPE duplicate state-year rows: 0\n",
      "States per year (tail):\n",
      "year\n",
      "2019    51\n",
      "2020    51\n",
      "2021    51\n",
      "2022    51\n",
      "2023    51\n",
      "Name: state, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>state_name</th>\n",
       "      <th>state_fips</th>\n",
       "      <th>year</th>\n",
       "      <th>poverty_rate</th>\n",
       "      <th>median_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>02</td>\n",
       "      <td>1989</td>\n",
       "      <td>10.6</td>\n",
       "      <td>33885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>02</td>\n",
       "      <td>1993</td>\n",
       "      <td>11.2</td>\n",
       "      <td>39431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>02</td>\n",
       "      <td>1995</td>\n",
       "      <td>10.1</td>\n",
       "      <td>42255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>02</td>\n",
       "      <td>1996</td>\n",
       "      <td>10.6</td>\n",
       "      <td>44797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>02</td>\n",
       "      <td>1997</td>\n",
       "      <td>11.2</td>\n",
       "      <td>43657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state state_name state_fips  year  poverty_rate  median_income\n",
       "0    AK     Alaska         02  1989          10.6          33885\n",
       "1    AK     Alaska         02  1993          11.2          39431\n",
       "2    AK     Alaska         02  1995          10.1          42255\n",
       "3    AK     Alaska         02  1996          10.6          44797\n",
       "4    AK     Alaska         02  1997          11.2          43657"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =====================================================\n",
    "# SAIPE: load pre-fetched, cleaned state-year parquet\n",
    "# =====================================================\n",
    "\n",
    "saipe = pd.read_parquet(SAIPE_PATH)\n",
    "\n",
    "expected = {\"state\", \"state_name\", \"state_fips\", \"year\", \"poverty_rate\", \"median_income\"}\n",
    "missing = expected - set(saipe.columns)\n",
    "assert not missing, f\"SAIPE is missing columns: {missing}\"\n",
    "\n",
    "# Types\n",
    "saipe[\"year\"] = pd.to_numeric(saipe[\"year\"], errors=\"raise\").astype(int)\n",
    "saipe[\"poverty_rate\"] = pd.to_numeric(saipe[\"poverty_rate\"], errors=\"coerce\")\n",
    "saipe[\"median_income\"] = pd.to_numeric(saipe[\"median_income\"], errors=\"coerce\")\n",
    "\n",
    "# Clean final\n",
    "saipe_clean = (\n",
    "    saipe[[\"state\", \"state_name\", \"state_fips\", \"year\", \"poverty_rate\", \"median_income\"]]\n",
    "    .dropna(subset=[\"state\", \"state_name\", \"year\", \"poverty_rate\", \"median_income\"])\n",
    "    .drop_duplicates(subset=[\"state\", \"year\"])\n",
    "    .sort_values([\"state\", \"year\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"SAIPE shape:\", saipe_clean.shape)\n",
    "print(\"SAIPE columns:\", saipe_clean.columns.tolist())\n",
    "print(\"SAIPE duplicate state-year rows:\", int(saipe_clean.duplicated([\"state\", \"year\"]).sum()))\n",
    "\n",
    "states_per_year = saipe_clean.groupby(\"year\")[\"state\"].nunique()\n",
    "print(\"States per year (tail):\")\n",
    "print(states_per_year.tail())\n",
    "\n",
    "# NOTE: 51 = 50 states + DC (Census SAIPE includes DC)\n",
    "assert states_per_year.min() == 51, f\"Expected 51 states+DC each year, got min={states_per_year.min()}\"\n",
    "\n",
    "display(saipe_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAUS rows: (233206, 5) | cols: ['series_id', 'year', 'period', 'value', 'footnote_codes']\n",
      "AREA rows: (8325, 6) | cols: ['area_type_code', 'area_code', 'area_text', 'display_level', 'selectable', 'sort_sequence']\n",
      "SERIES rows: (33881, 12) | cols: ['series_id', 'area_type_code', 'area_code', 'measure_code', 'seasonal', 'srd_code', 'series_title', 'footnote_codes', 'begin_year', 'begin_period', 'end_year', 'end_period']\n",
      "LAUS clean shape: (2499, 3)\n",
      "LAUS states covered: 51\n",
      "Duplicate state-year rows: 0\n",
      "States per year (tail):\n",
      "year\n",
      "2020    51\n",
      "2021    51\n",
      "2022    51\n",
      "2023    51\n",
      "2024    51\n",
      "Name: state, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>unemployment_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>AK</td>\n",
       "      <td>1980</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state  year  unemployment_rate\n",
       "53    AK  1980                9.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =====================================================\n",
    "# LAUS: State-level unemployment rate (annual averages)\n",
    "# =====================================================\n",
    "\n",
    "def load_laus_tsv(path):\n",
    "    # Load BLS tab-delimited files and strip whitespace everywhere.\n",
    "    df = pd.read_csv(path, sep=\"\\t\", dtype=str)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    for c in df.columns:\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "laus      = load_laus_tsv(LAUS_DATA_PATH)\n",
    "la_area   = load_laus_tsv(LAUS_AREA_PATH)\n",
    "la_series = load_laus_tsv(LAUS_SERIES_PATH)\n",
    "\n",
    "print(\"LAUS rows:\", laus.shape, \"| cols:\", laus.columns.tolist())\n",
    "print(\"AREA rows:\", la_area.shape, \"| cols:\", la_area.columns.tolist())\n",
    "print(\"SERIES rows:\", la_series.shape, \"| cols:\", la_series.columns.tolist())\n",
    "\n",
    "# 1) State lookup (area_code → state_name)\n",
    "la_states = (\n",
    "    la_area\n",
    "    .loc[la_area[\"area_type_code\"] == \"A\", [\"area_code\", \"area_text\"]]\n",
    "    .rename(columns={\"area_text\": \"state_name\"})\n",
    ")\n",
    "\n",
    "# 2) Unemployment RATE series (keep area_code)\n",
    "urate_series = (\n",
    "    la_series\n",
    "    .loc[la_series[\"measure_code\"] == \"03\", [\"series_id\", \"area_code\"]]\n",
    ")\n",
    "\n",
    "# 3) Merge LAUS data with series metadata (adds area_code), keep annual avg (M13)\n",
    "laus_merged = (\n",
    "    laus\n",
    "    .merge(urate_series, on=\"series_id\", how=\"inner\")\n",
    "    .loc[lambda d: d[\"period\"] == \"M13\"]\n",
    ")\n",
    "\n",
    "# 4) Attach state name using area_code\n",
    "laus_merged = laus_merged.merge(la_states, on=\"area_code\", how=\"inner\")\n",
    "\n",
    "# 5) Final clean\n",
    "laus_merged[\"year\"] = pd.to_numeric(laus_merged[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "laus_merged[\"unemployment_rate\"] = pd.to_numeric(laus_merged[\"value\"], errors=\"coerce\")\n",
    "\n",
    "laus_clean = (\n",
    "    laus_merged[[\"state_name\", \"year\", \"unemployment_rate\"]]\n",
    "    .dropna()\n",
    "    .drop_duplicates(subset=[\"state_name\", \"year\"])\n",
    "    .sort_values([\"state_name\", \"year\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Drop Puerto Rico (keep 50 + DC)\n",
    "laus_clean = laus_clean[laus_clean[\"state_name\"] != \"Puerto Rico\"].copy()\n",
    "\n",
    "# Map state_name -> USPS using SAIPE mapping\n",
    "name_to_usps = dict(zip(saipe_clean[\"state_name\"], saipe_clean[\"state\"]))\n",
    "laus_clean[\"state\"] = laus_clean[\"state_name\"].map(name_to_usps)\n",
    "\n",
    "bad = laus_clean.loc[laus_clean[\"state\"].isna(), \"state_name\"].value_counts()\n",
    "if len(bad) > 0:\n",
    "    raise ValueError(f\"Unmapped state names coming from LAUS:\\n{bad}\")\n",
    "\n",
    "laus_clean[\"year\"] = laus_clean[\"year\"].astype(int)\n",
    "laus_clean = laus_clean[[\"state\", \"year\", \"unemployment_rate\"]].copy()\n",
    "\n",
    "print(\"LAUS clean shape:\", laus_clean.shape)\n",
    "print(\"LAUS states covered:\", laus_clean[\"state\"].nunique())\n",
    "print(\"Duplicate state-year rows:\", int(laus_clean.duplicated([\"state\",\"year\"]).sum()))\n",
    "print(\"States per year (tail):\")\n",
    "print(laus_clean.groupby(\"year\")[\"state\"].nunique().tail())\n",
    "\n",
    "display(laus_clean.sample(1, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\projects\\python-policy-project\\data\\processed\\state_year_panel.parquet\n",
      "Saved: C:\\projects\\python-policy-project\\data\\processed\\state_year_panel.csv\n",
      "Missing unemployment_rate share: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>state_name</th>\n",
       "      <th>state_fips</th>\n",
       "      <th>year</th>\n",
       "      <th>poverty_rate</th>\n",
       "      <th>median_income</th>\n",
       "      <th>unemployment_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>02</td>\n",
       "      <td>1989</td>\n",
       "      <td>10.6</td>\n",
       "      <td>33885</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>02</td>\n",
       "      <td>1993</td>\n",
       "      <td>11.2</td>\n",
       "      <td>39431</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>02</td>\n",
       "      <td>1995</td>\n",
       "      <td>10.1</td>\n",
       "      <td>42255</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>02</td>\n",
       "      <td>1996</td>\n",
       "      <td>10.6</td>\n",
       "      <td>44797</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>02</td>\n",
       "      <td>1997</td>\n",
       "      <td>11.2</td>\n",
       "      <td>43657</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>02</td>\n",
       "      <td>1998</td>\n",
       "      <td>10.8</td>\n",
       "      <td>47177</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>02</td>\n",
       "      <td>1999</td>\n",
       "      <td>8.8</td>\n",
       "      <td>49133</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>02</td>\n",
       "      <td>2000</td>\n",
       "      <td>8.5</td>\n",
       "      <td>51433</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>02</td>\n",
       "      <td>2001</td>\n",
       "      <td>8.7</td>\n",
       "      <td>52332</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>02</td>\n",
       "      <td>2002</td>\n",
       "      <td>9.3</td>\n",
       "      <td>51844</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state state_name state_fips  year  poverty_rate  median_income  \\\n",
       "0    AK     Alaska         02  1989          10.6          33885   \n",
       "1    AK     Alaska         02  1993          11.2          39431   \n",
       "2    AK     Alaska         02  1995          10.1          42255   \n",
       "3    AK     Alaska         02  1996          10.6          44797   \n",
       "4    AK     Alaska         02  1997          11.2          43657   \n",
       "5    AK     Alaska         02  1998          10.8          47177   \n",
       "6    AK     Alaska         02  1999           8.8          49133   \n",
       "7    AK     Alaska         02  2000           8.5          51433   \n",
       "8    AK     Alaska         02  2001           8.7          52332   \n",
       "9    AK     Alaska         02  2002           9.3          51844   \n",
       "\n",
       "   unemployment_rate  \n",
       "0                7.1  \n",
       "1                7.8  \n",
       "2                7.3  \n",
       "3                7.5  \n",
       "4                7.0  \n",
       "5                6.3  \n",
       "6                6.4  \n",
       "7                6.3  \n",
       "8                6.3  \n",
       "9                7.2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panel years: 1989 to 2023\n",
      "How many years? 31\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# Merge into final panel + save\n",
    "# =====================================================\n",
    "\n",
    "panel = (\n",
    "    saipe_clean\n",
    "    .merge(laus_clean, on=[\"state\", \"year\"], how=\"left\", validate=\"1:1\")\n",
    "    .sort_values([\"state\", \"year\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "out_parquet = PROCESSED / \"state_year_panel.parquet\"\n",
    "out_csv     = PROCESSED / \"state_year_panel.csv\"\n",
    "\n",
    "panel.to_parquet(out_parquet, index=False)\n",
    "panel.to_csv(out_csv, index=False)\n",
    "\n",
    "print(\"Saved:\", out_parquet)\n",
    "print(\"Saved:\", out_csv)\n",
    "print(\"Missing unemployment_rate share:\", float(panel[\"unemployment_rate\"].isna().mean()))\n",
    "\n",
    "display(panel.head(10))\n",
    "print(\"Panel years:\", int(panel[\"year\"].min()), \"to\", int(panel[\"year\"].max()))\n",
    "print(\"How many years?\", int(panel[\"year\"].nunique()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
